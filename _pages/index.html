---
layout: single 
permalink: /
author_profile: true
title: "About Me"
description: "Alexis Ross's Website"
---

Hi, I'm Alexis! I'm a Predoctoral Young Investigator on the <a href = "https://allennlp.org/">AllenNLP team</a> at the <a href = "https://allenai.org/">Allen Institute for Artificial Intelligence (AI2)</a> working with Matt Peters and <a href = "https://www.anamarasovic.com/">Ana Marasovic</a>. I'm broadly interested in explainable/interpretable machine learning, natural language understanding, and especially the intersection of the two.

<br><br>

I recently graduated with a joint degree in Computer Science and Philosophy from Harvard, where I wote a senior thesis on causal explanations of machine learning models, advised by <a href = "https://himalakkaraju.github.io/">Hima Lakkaraju</a> and <a href = "https://scholar.harvard.edu/bernhardnickel">Bernhard Nickel</a>. I've spent time at Microsoft Research interning on <a href = "https://www.microsoft.com/en-us/research/project/project-hanover/">Project Hanover</a> with <a href = "https://www.microsoft.com/en-us/research/people/tristan/">Tristan Naumann</a> and <a href = "https://www.microsoft.com/en-us/research/people/hoifung/">Hoifung Poon</a> on biomedical machine reading for precision medicine. I've also been fortunate to have worked closely with <a href = "https://cs.brown.edu/people/epavlick/">Ellie Pavlick</a> and the rest of the <a href = "https://jsalt18-sentence-repl.github.io/">Sentence Representation Learning Team</a> at JSALT 2018. 

<br><br>I can be reached via email at alexisr [at] allenai [dot] org.

<br><br>

<h1>Publications</h1>

<ul>

	<li><strong>Alexis Ross</strong>, Ana Marasovic, and Matt Peters. <u>Explaining NLP Models via Minimal Contrastive Editing (MiCE)</u>. <i>Preprint</i>.<br>[<a href = "https://arxiv.org/pdf/2012.13985.pdf">Paper</a>] [<a href = "../assets/bibtex/explaining_mice.bib">BibTex</a>]</li>

	<li><strong>Alexis Ross</strong> and Ellie Pavlick. <u>How well do NLI models capture verb veridicality?</u> <i>EMNLP, 2019</i>. <strong>Oral Presentation</strong><br>[<a href="https://www.aclweb.org/anthology/D19-1228.pdf">Paper</a>] [<a href="../assets/pdfs/verb_veridicality_supplement.pdf">Supplement</a>] [<a href="../assets/pdfs/verb_veridicality_slides.pdf">Slides</a>] [<a href="https://github.com/alexisjihyeross/verb_veridicality">Dataset</a>] [<a href="../assets/bibtex/verb_veridicality.bib">BibTex</a>]</li>

	<li>Najoung Kim, Roma Patel, Adam Poliak, Alex Wang, Patrick Xia, Tom McCoy, Ian Tenney, <strong>Alexis Ross</strong>, Tal Linzen, Benjamin Van Durme, Sam Bowman, and Ellie Pavlick. <u>Probing what different NLP tasks teach machines about function word comprehension</u>. <i>*SEM, 2019</i>.<strong>Best Paper Award</strong><br>[<a href = "https://www.aclweb.org/anthology/S19-1026v2.pdf">Paper</a>] [<a href = "../assets/bibtex/function_words.bib">BibTex</a>]</li>

</ul>