---
title:  "Publications"
layout: archive 
classes: 
  - wide
permalink: /publications/
author_profile: true
comments: true
---
<h2>2025</h2>
<ul>
	<li>
		<a href = "https://arxiv.org/abs/2406.11830">Language Modeling with Editable External Knowledge</a>
		<br>Belinda Z. Li, Emmy Liu, <strong>Alexis Ross</strong>, Abbas Zeitoun, Graham Neubig, Jacob Andreas
		<br><i>NAACL, 2025</i>
	</li>
</ul>

<h2>2024</h2>
<ul>
	<li>
		<a href = "https://arxiv.org/abs/2405.04495">Toward In-Context Teaching: Adapting Examples to Students' Misconceptions</a>
		<br><strong>Alexis Ross</strong> and Jacob Andreas.
		<br><i>ACL, 2024</i>
	</li>
	<li>
		<a href = "https://arxiv.org/abs/2306.12587">ARIES: A Corpus of Scientific Paper Edits Made in Response to Peer Reviews</a>
		<br>Mike D'Arcy, <strong>Alexis Ross</strong>, Erin Bransom, Bailey Kuehl, Jonathan Bragg, Tom Hope, Doug Downey
		<br><i>ACL, 2024</i>
	</li>
	<li>
		<a href = "https://arxiv.org/abs/2307.02477">Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks</a>
		<br>Zhaofeng Wu, Linlu Qiu, <strong>Alexis Ross</strong>, Ekin Akyürek, Boyuan Chen, Bailin Wang, Najoung Kim, Jacob Andreas, Yoon Kim
		<br><i>NAACL, 2024</i>
	</li>
	
	
</ul>

<h2>2023</h2>
<ul>
	<li>
		<a href = "https://arxiv.org/abs/2305.17075">CREST: A Joint Framework for Rationalization and Counterfactual Text Generation</a>
		<br>Marcos Treviso, <strong>Alexis Ross</strong>, Nuno M. Guerreiro, André F. T. Martins 
		<br><i>ACL, 2023</i>
	</li>
	<li>
		<a href = "https://arxiv.org/abs/2306.09479">Inverse Scaling: When Bigger Isn't Better</a>
		<br>Ian R. McKenzie, ..., <strong>Alexis Ross (winning task author)</strong>, ... Najoung Kim, Samuel R. Bowman, Ethan Perez
		<br><i>TMLR, 2023</i>
	</li>
</ul>


<h2>2022</h2>

<ul>
	<li>
		<a href = "https://arxiv.org/abs/2210.13575">Does Self-Rationalization Improve Robustness to Spurious Correlations?</a>
		<br><strong>Alexis Ross</strong>, Matthew E. Peters, Ana Marasovic 
		<br><i>EMNLP, 2022</i>
	</li>
	<li>
		<a href = "https://arxiv.org/abs/2107.07150">Tailor: Generating and Perturbing Text with Semantic Controls</a>
		<br><strong>Alexis Ross*</strong>, Tongshuang Wu*, Hao Peng, Matthew E. Peters, Matt Gardner
		<br><i>ACL, 2022</i>
		<br>[<a href = "../assets/bibtex/tailor.bib">BibTex</a>] [<a href = "https://github.com/allenai/tailor">Code</a>] [<a href = "https://underline.io/events/284/sessions/10682/lecture/49848-tailor-generating-and-perturbing-text-with-semantic-controls">Video</a>] [<a href="https://huggingface.co/allenai/tailor">Generator</a>]
	</li>
</ul>
<h2>2021</h2>

<ul>
	<li>
		<a href = "https://arxiv.org/abs/2011.06146">Learning Models for Actionable Recourse</a>
		<br><strong>Alexis Ross</strong>, Himabindu Lakkaraju, Osbert Bastani
		<br><i>NeurIPS, 2021</i>
	</li>

	<li>
		<a href = "https://arxiv.org/abs/2104.08646">Competency Problems: On Finding and Removing Artifacts in Language Data</a>
		<br>Matt Gardner*, William Merrill*, Jesse Dodge, Matthew E. Peters, <strong>Alexis Ross</strong>, Sameer Singh, Noah Smith
		<br><i>EMNLP, 2021</i>
		<br>[<a href = "../assets/bibtex/competency.bib">BibTex</a>]
	</li>

	<li>
		<a href = "https://aclanthology.org/2021.findings-acl.336.pdf">Explaining NLP Models via Minimal Contrastive Editing (MiCE)</a>
		<br><strong>Alexis Ross</strong>, Ana Marasovic, Matthew E. Peters
		<br><i>Findings of ACL, 2021</i>
		<br>[<a href = "../assets/bibtex/explaining_mice.bib">BibTex</a>] [<a href="https://github.com/allenai/mice">Code</a>] [<a href="https://underline.io/lecture/26427-explaining-nlp-models-via-minimal-contrastive-editing-(mice)">Video</a>]
	</li>
</ul>

<h2>2019</h2>

<ul>
	<li>
		<a href = "https://aclanthology.org/D19-1228/">How well do NLI models capture verb veridicality?</a> 
		<br><strong>Alexis Ross</strong> and Ellie Pavlick
		<br><i>EMNLP, 2019</i> 
		<br><strong>Oral Presentation</strong>
		<br>[<a href="../assets/bibtex/verb_veridicality.bib">BibTex</a>] [<a href="https://github.com/alexisjihyeross/verb_veridicality">Dataset</a>] [<a href="../assets/pdfs/verb_veridicality_supplement.pdf">Supplement</a>] [<a href="../assets/pdfs/verb_veridicality_slides.pdf">Slides</a>] 
	</li> 

	<li>
		<a href = "https://aclanthology.org/S19-1026/">Probing what different NLP tasks teach machines about function word comprehension</a>
		<br>Najoung Kim, Roma Patel, Adam Poliak, Alex Wang, Patrick Xia, Tom McCoy, Ian Tenney, <strong>Alexis Ross</strong>, Tal Linzen, Benjamin Van Durme, Sam Bowman, Ellie Pavlick
		<br><i>*SEM, 2019</i> 
		<br><strong>Best Paper Award</strong>
		<br>[<a href = "../assets/bibtex/function_words.bib">BibTex</a>]
	</li>

</ul>

<h1>Other Projects</h1>

<ul>
	<li>
		<a href = "https://dash.harvard.edu/bitstream/handle/1/37364684/ROSS-SENIORTHESIS-2020.pdf?isAllowed=y&sequence=1">Using Linear Approximations to Explain Complex, Blackbox Classifiers</a>
		<br>Advised by Hima Lakkaraju and Bernhard Nickel. 
		<br><i>Senior Thesis, Computer Science and Philosophy, 2020</i>. 
		<br><strong>Hoopes Prize</strong>
	</li>
</ul>
